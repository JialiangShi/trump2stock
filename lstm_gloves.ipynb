{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I will be announcing my Second Term Presidenti...</td>\n",
       "      <td>05-31-2019 20:35:41</td>\n",
       "      <td>35248</td>\n",
       "      <td>128039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter Media Studio</td>\n",
       "      <td>GREAT NEWS! #MAGA https://t.co/91Yk8B11bP</td>\n",
       "      <td>05-31-2019 20:02:16</td>\n",
       "      <td>20493</td>\n",
       "      <td>75339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>As we celebrate LGBT Pride Month and recognize...</td>\n",
       "      <td>05-31-2019 19:12:32</td>\n",
       "      <td>28936</td>\n",
       "      <td>136614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>....on the basis of their sexual orientation. ...</td>\n",
       "      <td>05-31-2019 19:12:32</td>\n",
       "      <td>20416</td>\n",
       "      <td>105421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>.@SeanHannity is having a DEEP STATE SHOW toni...</td>\n",
       "      <td>05-31-2019 18:11:25</td>\n",
       "      <td>18257</td>\n",
       "      <td>65602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source                                               text  \\\n",
       "0    Twitter for iPhone  I will be announcing my Second Term Presidenti...   \n",
       "1  Twitter Media Studio          GREAT NEWS! #MAGA https://t.co/91Yk8B11bP   \n",
       "2    Twitter for iPhone  As we celebrate LGBT Pride Month and recognize...   \n",
       "3    Twitter for iPhone  ....on the basis of their sexual orientation. ...   \n",
       "4    Twitter for iPhone  .@SeanHannity is having a DEEP STATE SHOW toni...   \n",
       "\n",
       "            created_at  retweet_count  favorite_count  \n",
       "0  05-31-2019 20:35:41          35248          128039  \n",
       "1  05-31-2019 20:02:16          20493           75339  \n",
       "2  05-31-2019 19:12:32          28936          136614  \n",
       "3  05-31-2019 19:12:32          20416          105421  \n",
       "4  05-31-2019 18:11:25          18257           65602  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    # Lowercase, trim, and remove non-letter charactersb\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return [w for w in s.split() if len(w) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['will',\n",
       " 'be',\n",
       " 'announcing',\n",
       " 'my',\n",
       " 'second',\n",
       " 'term',\n",
       " 'presidential',\n",
       " 'run',\n",
       " 'with',\n",
       " 'first',\n",
       " 'lady',\n",
       " 'melania',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'mike',\n",
       " 'pence',\n",
       " 'and',\n",
       " 'second',\n",
       " 'lady',\n",
       " 'karen',\n",
       " 'pence',\n",
       " 'on',\n",
       " 'june',\n",
       " 'th',\n",
       " 'in',\n",
       " 'orlando',\n",
       " 'florida',\n",
       " 'at',\n",
       " 'the',\n",
       " 'seat',\n",
       " 'amway',\n",
       " 'center',\n",
       " 'join',\n",
       " 'us',\n",
       " 'for',\n",
       " 'this',\n",
       " 'historic',\n",
       " 'rally',\n",
       " 'tickets',\n",
       " 'https',\n",
       " '.co',\n",
       " 'krdp',\n",
       " 'oqvg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.loc[0, 'text']\n",
    "normalizeString(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['words'] = df['text'].apply(normalizeString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>I will be announcing my Second Term Presidenti...</td>\n",
       "      <td>05-31-2019 20:35:41</td>\n",
       "      <td>35248</td>\n",
       "      <td>128039</td>\n",
       "      <td>[will, be, announcing, my, second, term, presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter Media Studio</td>\n",
       "      <td>GREAT NEWS! #MAGA https://t.co/91Yk8B11bP</td>\n",
       "      <td>05-31-2019 20:02:16</td>\n",
       "      <td>20493</td>\n",
       "      <td>75339</td>\n",
       "      <td>[great, news, maga, https, .co, yk, bp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>As we celebrate LGBT Pride Month and recognize...</td>\n",
       "      <td>05-31-2019 19:12:32</td>\n",
       "      <td>28936</td>\n",
       "      <td>136614</td>\n",
       "      <td>[as, we, celebrate, lgbt, pride, month, and, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>....on the basis of their sexual orientation. ...</td>\n",
       "      <td>05-31-2019 19:12:32</td>\n",
       "      <td>20416</td>\n",
       "      <td>105421</td>\n",
       "      <td>[.on, the, basis, of, their, sexual, orientati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>.@SeanHannity is having a DEEP STATE SHOW toni...</td>\n",
       "      <td>05-31-2019 18:11:25</td>\n",
       "      <td>18257</td>\n",
       "      <td>65602</td>\n",
       "      <td>[seanhannity, is, having, deep, state, show, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 source                                               text  \\\n",
       "0    Twitter for iPhone  I will be announcing my Second Term Presidenti...   \n",
       "1  Twitter Media Studio          GREAT NEWS! #MAGA https://t.co/91Yk8B11bP   \n",
       "2    Twitter for iPhone  As we celebrate LGBT Pride Month and recognize...   \n",
       "3    Twitter for iPhone  ....on the basis of their sexual orientation. ...   \n",
       "4    Twitter for iPhone  .@SeanHannity is having a DEEP STATE SHOW toni...   \n",
       "\n",
       "            created_at  retweet_count  favorite_count  \\\n",
       "0  05-31-2019 20:35:41          35248          128039   \n",
       "1  05-31-2019 20:02:16          20493           75339   \n",
       "2  05-31-2019 19:12:32          28936          136614   \n",
       "3  05-31-2019 19:12:32          20416          105421   \n",
       "4  05-31-2019 18:11:25          18257           65602   \n",
       "\n",
       "                                               words  \n",
       "0  [will, be, announcing, my, second, term, presi...  \n",
       "1            [great, news, maga, https, .co, yk, bp]  \n",
       "2  [as, we, celebrate, lgbt, pride, month, and, r...  \n",
       "3  [.on, the, basis, of, their, sexual, orientati...  \n",
       "4  [seanhannity, is, having, deep, state, show, t...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_length = df['words'].apply(len).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 7, 44, 26, 27, 46, 45, 50, 44, 31]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_length[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(tweet_length, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(tweet_length, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 90% of tweets have less than 47 words, therfore we choose 45 as our padding size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile=\"/Users/jialiang.shi/data/glove.6B/glove.6B.50d.txt\"):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    f.close()\n",
    "    return word_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vecs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = df['words'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "ws = list(itertools.chain(*df_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199003"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter()\n",
    "word_count.update(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13292"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete if occurs < 5 times and it is not in our pretrained embeddings\n",
    "for word in list(word_count):\n",
    "    if word_count[word] < 5 and word not in word_vecs:\n",
    "        del word_count[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9991"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in word_count.keys():\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9993"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There are 9993 words in our vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained weights for the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_word_vector(D=50):\n",
    "    \"\"\"Create arandom word vector\n",
    "    \n",
    "    0.25 is chosen so the unknown vectors have (approximately) same variance \n",
    "    as pre-trained ones\n",
    "    \"\"\"\n",
    "    return np.random.uniform(-0.25,0.25,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(word_vecs, vocab2index, words, D=50):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    V = len(words)\n",
    "    W = np.zeros((V, D), dtype=\"float32\")\n",
    "    W[0] = np.zeros(D, dtype='float32')\n",
    "    i = 1\n",
    "    for i in range(1, V):\n",
    "        if words[i] in word_vecs:\n",
    "            W[i] = word_vecs[words[i]]\n",
    "        else:\n",
    "            W[i] = random_word_vector()\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9993, 50)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = create_embedding_matrix(word_vecs, vocab2index, words)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence, vocab2index, N=20, padding_start=True):\n",
    "    x = normalizeString(sentence)\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
    "    l = min(N, len(enc1))\n",
    "    if padding_start:\n",
    "        enc[:l] = enc1[:l]\n",
    "    else:\n",
    "        enc[N-l:] = enc1[:l]\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I will be announcing my Second Term Presidential Run with First Lady Melania Vice President Mike Pence and Second Lady Karen Pence on June 18th in Orlando Florida at the 20000 seat Amway Center. Join us for this Historic Rally! Tickets: https://t.co/1krDP2oQvG'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.loc[0,'text']\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        6, 12, 19, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,\n",
       "       33, 34, 35, 36, 37, 38, 39,  1,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_sentence(sample, vocab2index, N=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, df, N=50, padding_start=True):\n",
    "        tweet = df['tweet'].tolist()\n",
    "        self.X = [encode_sentence(q, vocab2index, N, padding_start) for q in tweet]\n",
    "        self.y = df['label'].values        \n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TweetDataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404290"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2,    3,    4,   14,   15,   16,   17,   18,   19,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    2,  108,\n",
       "         820,  302,    4,  427,  197, 4396,    4,   16,   17,   18,   19,\n",
       "         243,    0,    0,    0,    0,    0,    0], dtype=int32), 0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_ds))\n",
    "test_size = len(train_ds) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(train_ds, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323432"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80858"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix) :\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "        self.embedding.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        out_pack, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics_v0(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y in valid_dl:\n",
    "        # s is not used here\n",
    "        x = x.long()\n",
    "        y = y.float().unsqueeze(1)\n",
    "        y_hat = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs_v0(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            # s is not used in this model\n",
    "            x = x.long()\n",
    "            y = y.float()\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics_v0(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60170"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60170, 50)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(vocab_size, 50, 25, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.627 val loss 0.610 and val accuracy 0.661\n",
      "train loss 0.571 val loss 0.575 and val accuracy 0.689\n",
      "train loss 0.555 val loss 0.564 and val accuracy 0.702\n",
      "train loss 0.549 val loss 0.547 and val accuracy 0.716\n"
     ]
    }
   ],
   "source": [
    "train_epocs_v0(model, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epocs_v0(model, epochs=10, lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, N=20, padding_start=True):\n",
    "        q1 = df['question1'].tolist()\n",
    "        q2 = df['question2'].tolist()\n",
    "        X1 = [encode_sentence(q, vocab2index, N, padding_start) for q in q1]\n",
    "        X2 = [encode_sentence(q, vocab2index, N, padding_start) for q in q2]\n",
    "        self.X = np.array([list(X1[i])+list(X2[i]) for i in range(len(df))])     \n",
    "      \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = TestDataset(test_df, padding_start=False)\n",
    "batch_size = 10000\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for x in test_dl:\n",
    "    # s is not used in this model\n",
    "    x = x.long()\n",
    "    y_pred = model(x)\n",
    "    prediction.extend(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['is_duplicate'] = prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
